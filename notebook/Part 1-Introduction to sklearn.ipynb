{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"figure/Pythontz-final.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the style globally\n",
    "# Alternatives include bmh, fivethirtyeight, ggplot,\n",
    "# dark_background, seaborn-deep, etc\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 12\n",
    "plt.rcParams['figure.figsize'] = 8, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure/ml_pipeline_large.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducing Scikit-Learn\n",
    "\n",
    "There are several Python libraries which provide solid implementations of a range of machine learning algorithms. One of the best known is [Scikit-Learn](http://scikit-learn.org/stable/):a package that provides efficient versions of a large number of common algorithms. \n",
    "- [Scikit-learn](http://scikit-learn.org/) is a Python open source library designed to tackle Machine Learning problems from beginning to end. \n",
    "- Built on NumPy, SciPy, and matplotlib\n",
    "- It is used and well praised by big companies like Evernote, Spotify etc as shown [here](http://scikit-learn.org/stable/testimonials/testimonials.html)\n",
    "\n",
    "We aims to give an accessible introduction to how to use machine learning techniques using [scikit-learn](http://scikit-learn.org/) for your own projects and datasets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  Scikit-Learn API\n",
    "\n",
    "Scikit-Learn is characterized by a clean, uniform, and streamlined API, as well as by very useful and complete online documentation.\n",
    "\n",
    "- **sklearn.datasets**: Includes utilities to load datasets, including methods to load and fetch popular reference datasets. It also features some artificial data generators.\n",
    "- **sklearn.feature_selection**: Implements feature selection algorithms. It currently includes univariate filter selection methods and the recursive feature elimination algorithm.\n",
    "- **sklearn.metrics**: includes score functions, performance metrics and pairwise metrics and distance computations.\n",
    "- **sklearn.naive_bayes**: implements Naive Bayes algorithms.\n",
    "\n",
    "## 1.2 Scikit-Learn's Estimator API\n",
    "\n",
    "Every machine learning algorithm in Scikit-Learn is implemented via the Estimator API, which provides a consistent interface for a wide range of machine learning applications.\n",
    "\n",
    "The steps in using the Scikit-Learn estimator API are as follows:\n",
    "\n",
    "- Arrange data into a features matrix and target vector following the discussion below in section 1.3.\n",
    "- Choose a class of model by importing the appropriate estimator class from Scikit-Learn.\n",
    "- Choose model hyperparameters by instantiating this class with desired values.\n",
    "   * Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments the estimator classes.\n",
    "- Fit the model to your data by calling the **fit()** method of the model instance.\n",
    "- Apply the Model to new data:\n",
    "  * For supervised learning, often we predict labels for unknown data using the **predict()** method.\n",
    "  * For unsupervised learning, we often transform or infer properties of the data using the **transform()** or **predict()** method.\n",
    "- Evaluate the model\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Representation in Scikit-Learn\n",
    "\n",
    "Machine learning is about creating models from data: for that reason, we'll start by discussing how data can be represented in order to be understood by the computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider set of data in dataframe with rows ad columns.Here each row of the data refers to a single observation, and the number of rows is the total number of observation in the dataset. In general, we will refer to the rows of the matrix as samples, and the number of rows as $n_{samples}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Likewise, each column of the data refers to a particular quantitative piece of information that describes each sample. In general, we will refer to the columns of the matrix as features, and the number of columns as $n_{features}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Features matrix\n",
    "\n",
    "A two-dimensional numerical array or matrix with shape [$n_{samples}$, $n_{features}$]. By convention, this features matrix is often stored in a variable named $X$.\n",
    "\n",
    "The samples (i.e., rows) always refer to the individual objects described by the dataset\n",
    "\n",
    "The features (i.e., columns) always refer to the distinct observations that describe each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Target array\n",
    "\n",
    "One dimensional, with length $n_{samples}$ usually the quantity we want to predict from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised learning example\n",
    "\n",
    "## 2.1  Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression, we are interested in predicting a scalar-valued target, such as the price of a stock. By linear, we mean that the target must be predicted as a linear function of the inputs.\n",
    "\n",
    "Consider the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([ 0.55623761,  0.55077588,  0.27762201,  0.95921018,  0.0956837 ,\n",
    "        0.64471549,  0.85149188,  0.55415515,  0.64489205,  0.25350928,\n",
    "        0.81841887,  0.76787552,  0.3463776 ,  0.42975755,  0.51326507,\n",
    "        0.88745242,  0.46700522,  0.11441181,  0.03528545,  0.72198726,\n",
    "        0.44392746,  0.60703492,  0.30947934,  0.97067108,  0.20131097,\n",
    "        0.55954679,  0.30072729,  0.70617522,  0.49736816,  0.20816487,\n",
    "        0.4141809 ,  0.93443168,  0.60429835,  0.41384493,  0.85989403,\n",
    "        0.07354739,  0.70199998,  0.36112765,  0.15749281,  0.61203265,\n",
    "        0.32702159,  0.98164674,  0.38167423,  0.67370885,  0.74778714,\n",
    "        0.28591757,  0.73423083,  0.20570086,  0.36095281,  0.01289089,\n",
    "        0.57648531,  0.06770663,  0.8807249 ,  0.72862818,  0.88651844,\n",
    "        0.82253656,  0.73449858,  0.57400562,  0.31775974,  0.79437578,\n",
    "        0.72936971,  0.17587664,  0.31999439,  0.06162332,  0.55069835,\n",
    "        0.07848318,  0.46367232,  0.88656963,  0.77054617,  0.15059656,\n",
    "        0.11075492,  0.47431977,  0.93649446,  0.11528399,  0.47179202,\n",
    "        0.44430952,  0.98095376,  0.81822356,  0.56687681,  0.34295983,\n",
    "        0.95481171,  0.9416362 ,  0.74449455,  0.08451585,  0.67201501,\n",
    "        0.33974494,  0.20535398,  0.31689309,  0.54419625,  0.45039334,\n",
    "        0.72623297,  0.23238259,  0.54935201,  0.5271361 ,  0.77528756,\n",
    "        0.16509066,  0.57407955,  0.53232159,  0.26991462,  0.58202651])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([ 1.09073178,  0.87705364,  0.53813056,  1.79756503,  0.44463208,\n",
    "        1.35371022,  1.7369022 ,  1.38874705,  1.44013509,  0.55237873,\n",
    "        1.73233007,  1.40347576,  0.66820119,  1.40709865,  0.93064174,\n",
    "        1.96278042,  0.86183487,  0.23826412,  0.24581197,  1.36426266,\n",
    "        0.69937493,  1.44757982,  0.43359181,  1.78991267,  0.19608985,\n",
    "        1.09347291,  0.4723643 ,  1.58549403,  0.50008317,  0.39941469,\n",
    "        0.81228127,  1.87523703,  1.32366021,  0.63414426,  1.67932234,\n",
    "       -0.23617384,  1.50180948,  0.26563214,  0.28739881,  1.28417294,\n",
    "        1.03433624,  1.96537267,  0.75855884,  1.71978389,  1.42698512,\n",
    "        0.48402125,  1.61960246,  0.24214051,  0.7609597 ,  0.40168762,\n",
    "        0.96582655,  0.42924411,  1.89036535,  1.28047164,  1.51244322,\n",
    "        1.71619123,  0.77025205,  1.40236634,  0.70047884,  1.64659947,\n",
    "        1.43503278,  0.07966009,  0.54599231,  0.54038079,  1.26614206,\n",
    "        0.24295371,  0.8902031 ,  1.64911025,  1.42968399,  0.53267405,\n",
    "        0.5634043 ,  1.00800583,  2.00998127,  0.08297076,  0.96948009,\n",
    "        0.92242496,  1.90523025,  1.26608053,  0.96106417,  0.3261506 ,\n",
    "        1.70010292,  2.11111934,  1.31668139,  0.31884149,  1.42518027,\n",
    "        0.78828978, -0.02135849,  0.59541044,  0.99515104,  0.79022447,\n",
    "        1.46546328,  0.34897952,  1.00840362,  0.9710038 ,  1.40021095,\n",
    "        0.25636884,  0.57547639,  1.60640628,  0.30321808,  1.28503417])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let use the above data to fit a simple linear regression $y=wx +b$ applying the steps in using the Scikit-Learn estimator API as presented in section 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y, s=50)\n",
    "plt.title('Scatter Plot')\n",
    "plt.xlabel('$X$')\n",
    "plt.ylabel('$y$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrange data into a features matrix and target vector\n",
    "\n",
    "Here our target variable $y$ feature matrix is $X$. Let check the shape of $y$ and $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the shape of target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the shape of $X$ it is 1D: We therefore need to massage the data X to make it a matrix of size [n_samples, n_features] as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[:, np.newaxis]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Let Choose a class of model\n",
    "\n",
    "Import  the linear regression class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** more general linear regression models exist as well follow this [link](http://scikit-learn.org/stable/modules/linear_model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate model and select hyperparameters\n",
    "\n",
    "This step involve defining the model with its associated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fit the model to your data\n",
    "\n",
    "Now it is time to apply our model to data. This can be done with the fit() method of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fit() command causes a number of model-dependent internal computations to take place, and the results of these computations are stored in model-specific attributes that the user can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Weight coefficients: ', model.coef_)\n",
    "print('y-axis intercept: ', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus our model is therefore: $$y = 1.928544x + 0.020108483042$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict labels for unknown data\n",
    "Once the model is trained, the main task of supervised machine learning is to evaluate it based on what it says about new data.\n",
    "\n",
    "For the sake of this example, our \"new data\" will be a grid of X values, and we will ask what y values the model predicts:\n",
    "\n",
    "Let select the last ten X data use our model to predict y variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = X[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let visualize the actual values vs predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_actual = y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_new, y_actual, color ='b',label=\"Actual\", s=80)\n",
    "plt.scatter(X_new, y_pred, color = 'g', label=\"prediction\", s=80)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Model Visualization')\n",
    "plt.xlabel('$X$')\n",
    "plt.ylabel('$y$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "There are 3 different APIs for evaluating the quality of a model’s predictions:\n",
    "\n",
    "- Estimator score method: Estimators have a score method providing a default evaluation criterion for the problem they are designed to solve. \n",
    "- Scoring parameter: Model-evaluation tools using cross-validation (such as model_selection.cross_val_score and model_selection.GridSearchCV) rely on an internal scoring strategy. \n",
    "- Metric functions: The metrics module implements functions assessing prediction error for specific purposes.  Classification metrics, Multilabel ranking metrics, Regression metrics and Clustering metrics.\n",
    "\n",
    "For details refer to this [link](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "\n",
    "For example the above regression problem we can find the Root Mean Square(RMS) as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Supervised learning: Classification.\n",
    "\n",
    "Our question will be this: given a model trained on a portion of admission data, Predict wether a student with given grades will be admitted or not.\n",
    "\n",
    "For this task, we will use an extremely simple logistic regression.\n",
    "\n",
    "We would like to evaluate the model on data it has not seen before, and so we will split the data into a training set and a testing set. \n",
    "\n",
    "This could be done by hand, but it is more convenient to use the **train_test_split utility** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admission = pd.read_csv('data/admission.csv', names = [\"grade1\", \"grade2\", \"remark\"])\n",
    "admission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data is two-dimensional, we can plot each sample as a point in a two-dimensional coordinate system, with the first feature being the x-axis and the second feature being the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admitted_1 =admission[admission['remark']==1]['grade1']\n",
    "admitted_2 =admission[admission['remark']==1]['grade2']\n",
    "not_admitted_1 =admission[admission['remark']==0]['grade1']\n",
    "not_admitted_2 =admission[admission['remark']==0]['grade2']\n",
    "\n",
    "plot_name = \"scatter_1\"\n",
    "plt.scatter(admitted_1,admitted_2,c='green',s=60)\n",
    "plt.scatter(not_admitted_1,not_admitted_2,c='red',s=60)\n",
    "plt.title('Scatter Plot')\n",
    "plt.xlabel('Grade 1')\n",
    "plt.ylabel('Grade 2')\n",
    "plt.legend(('Admitted','Not admitted'),scatterpoints=1,loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a supervised task, and since we are interested in its performance on unseen data, we split our data into two parts:\n",
    "\n",
    "* a training set that the learning algorithm uses to fit the model\n",
    "* a test set to evaluate the generalization performance of the model\n",
    "\n",
    "The train_test_split function from the model_selection module does that for us -- we will use it to split a dataset into 75% training data and 25% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['grade1', 'grade2']\n",
    "X = admission[features]\n",
    "y = admission.remark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   # 1. choose model class\n",
    "model = LogisticRegression()                          # 2. instantiate model\n",
    "model.fit(X_train, y_train)                           # 3. fit model to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. predict on new data\n",
    "y_pred = model.predict(X_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate our classifier quantitatively by measuring what fraction of predictions is correct. This is called accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_acc  = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy: {}\" .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clear that our model achieve a test accuracy of $96\\%$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another classifier: K Nearest Neighbors¶\n",
    "Another popular and easy to understand classifier is K nearest neighbors (kNN). It has one of the simplest learning strategies: given a new, unknown observation, look up in your reference database which ones have the closest features and assign the predominant class.\n",
    "\n",
    "The interface is exactly the same as for LogisticRegression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining the model with its associated parameters\n",
    "from sklearn.neighbors import KNeighborsClassifier       # 1. choose model class\n",
    "knn = KNeighborsClassifier(n_neighbors=2)               # 2. instantiate model\n",
    "knn.fit(X_train, y_train)                                # 3. fit model to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. predict on new data\n",
    "y_pred = knn.predict(X_test)                      \n",
    "test_acc  = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy: {}\" .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clear that our model achieve a test accuracy of $80\\%$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise¶\n",
    "Play with different values of the n_neighbors and observe how test accuracy change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another classifier:  RANDOM FOREST¶\n",
    "\n",
    "A random forest is a 'meta estimator'. It will fit a number of decision trees (we'll have to tell it how many) on various sub-samples of the dataset. Then it will use averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rForest = RandomForestClassifier(n_estimators=10)\n",
    "rForest.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rForest.predict(X_test)                      \n",
    "test_acc  = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy: {}\" .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clear that our model achieve a test accuracy of $92\\%$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise¶\n",
    "Play with different values of the n_estimators and observe how  test accuracy change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Introduction to Machine Learning in Python with scikit-learn](http://ipython-books.github.io/featured-04/)\n",
    "* [Introduction to Machine Learning with Python](https://github.com/amueller/introduction_to_ml_with_python)\n",
    "* [Scikit-learn tutorial at SciPy2016](https://github.com/amueller/scipy-2016-sklearn)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
